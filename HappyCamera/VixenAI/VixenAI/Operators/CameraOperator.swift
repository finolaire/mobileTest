//
//  VixenCameraOperator.swift
//  VixenAI
//
//  ç›¸æœºç®¡ç†å™¨
//

import SwiftUI
import AVFoundation

class VixenCameraOperator: NSObject, ObservableObject {
    
    @Published var session = AVCaptureSession()
    @Published var capturedImage: UIImage?
    @Published var isSessionRunning = false
    @Published var cameraPermissionGranted = false
    @Published var isFlashOn = false
    @Published var isTorchOn = false  // æ‰‹ç”µç­’çŠ¶æ€
    @Published var currentFilter: String = "CIPhotoEffectNone"  // å½“å‰æ»¤é•œ
    
    private var videoDeviceInput: AVCaptureDeviceInput?
    private let photoOutput = AVCapturePhotoOutput()
    private var currentCameraPosition: AVCaptureDevice.Position = .back
    
    // ä¿å­˜å–æ™¯æ¡†ä¿¡æ¯ï¼Œç”¨äºç²¾ç¡®è£å‰ª
    var viewportRect: CGRect = .zero
    weak var previewLayer: AVCaptureVideoPreviewLayer?
    weak var previewView: UIView?  // æ–°çš„é¢„è§ˆè§†å›¾å¼•ç”¨
    
    // MARK: - æ£€æŸ¥ç›¸æœºæƒé™
    func checkCameraPermission() {
        switch AVCaptureDevice.authorizationStatus(for: .video) {
        case .authorized:
            cameraPermissionGranted = true
            setupCamera()
        case .notDetermined:
            AVCaptureDevice.requestAccess(for: .video) { [weak self] granted in
                DispatchQueue.main.async {
                    self?.cameraPermissionGranted = granted
                    if granted {
                        self?.setupCamera()
                    }
                }
            }
        case .denied, .restricted:
            cameraPermissionGranted = false
        @unknown default:
            cameraPermissionGranted = false
        }
    }
    
    // MARK: - è®¾ç½®ç›¸æœº
    func setupCamera() {
        session.beginConfiguration()
        session.sessionPreset = .photo
        
        guard let videoDevice = AVCaptureDevice.default(.builtInWideAngleCamera,
                                                        for: .video,
                                                        position: currentCameraPosition) else {
            session.commitConfiguration()
            return
        }
        
        do {
            let videoDeviceInput = try AVCaptureDeviceInput(device: videoDevice)
            
            if session.canAddInput(videoDeviceInput) {
                session.addInput(videoDeviceInput)
                self.videoDeviceInput = videoDeviceInput
            }
            
            if session.canAddOutput(photoOutput) {
                session.addOutput(photoOutput)
                photoOutput.maxPhotoQualityPrioritization = .quality
            }
            
            session.commitConfiguration()
        } catch {
            print("ç›¸æœºè®¾ç½®å¤±è´¥: \(error.localizedDescription)")
            session.commitConfiguration()
        }
    }
    
    // MARK: - å¼€å§‹ä¼šè¯
    func startSession() {
        guard !isSessionRunning else { return }
        DispatchQueue.global(qos: .userInitiated).async { [weak self] in
            self?.session.startRunning()
            DispatchQueue.main.async {
                self?.isSessionRunning = true
            }
        }
    }
    
    // MARK: - åœæ­¢ä¼šè¯
    func stopSession() {
        guard isSessionRunning else { return }
        
        // åœæ­¢ä¼šè¯å‰å…ˆå…³é—­æ‰‹ç”µç­’
        if isTorchOn {
            toggleTorch()
        }
        
        DispatchQueue.global(qos: .userInitiated).async { [weak self] in
            self?.session.stopRunning()
            DispatchQueue.main.async {
                self?.isSessionRunning = false
            }
        }
    }
    
    // MARK: - æ‹ç…§
    func capturePhoto() {
        let settings = AVCapturePhotoSettings()
        
        // è®¾ç½®é—ªå…‰ç¯
        if let device = videoDeviceInput?.device, device.hasFlash {
            settings.flashMode = isFlashOn ? .on : .off
        }
        
        if let photoOutputConnection = photoOutput.connection(with: .video) {
            if #available(iOS 17.0, *) {
                photoOutputConnection.videoRotationAngle = 0
            } else {
                photoOutputConnection.videoOrientation = .portrait
            }
        }
        photoOutput.capturePhoto(with: settings, delegate: self)
    }
    
    // MARK: - åˆ‡æ¢é—ªå…‰ç¯
    func toggleFlash() {
        isFlashOn.toggle()
    }
    
    // MARK: - åˆ‡æ¢æ‘„åƒå¤´
    func switchCamera() {
        guard let currentInput = videoDeviceInput else { return }
        
        // åˆ‡æ¢æ‘„åƒå¤´å‰å…ˆå…³é—­æ‰‹ç”µç­’
        if isTorchOn {
            toggleTorch()
        }
        
        session.beginConfiguration()
        session.removeInput(currentInput)
        
        currentCameraPosition = currentCameraPosition == .back ? .front : .back
        
        guard let videoDevice = AVCaptureDevice.default(.builtInWideAngleCamera,
                                                        for: .video,
                                                        position: currentCameraPosition),
              let newVideoInput = try? AVCaptureDeviceInput(device: videoDevice) else {
            session.addInput(currentInput)
            session.commitConfiguration()
            return
        }
        
        if session.canAddInput(newVideoInput) {
            session.addInput(newVideoInput)
            videoDeviceInput = newVideoInput
        } else {
            session.addInput(currentInput)
        }
        
        session.commitConfiguration()
    }
    
    // MARK: - é‡ç½®
    func reset() {
        capturedImage = nil
    }
    
    // MARK: - ç‚¹å‡»å¯¹ç„¦
    func focusAndExposure(at point: CGPoint) {
        guard let device = videoDeviceInput?.device else { return }
        
        do {
            try device.lockForConfiguration()
            
            // è®¾ç½®å¯¹ç„¦
            if device.isFocusPointOfInterestSupported && device.isFocusModeSupported(.autoFocus) {
                device.focusPointOfInterest = point
                device.focusMode = .autoFocus
            }
            
            // è®¾ç½®æ›å…‰
            if device.isExposurePointOfInterestSupported && device.isExposureModeSupported(.autoExpose) {
                device.exposurePointOfInterest = point
                device.exposureMode = .autoExpose
            }
            
            device.unlockForConfiguration()
        } catch {
            print("å¯¹ç„¦å¤±è´¥: \(error.localizedDescription)")
        }
    }
    
    // MARK: - è°ƒèŠ‚äº®åº¦ï¼ˆæ›å…‰è¡¥å¿ï¼‰
    func setBrightness(_ value: Double) {
        guard let device = videoDeviceInput?.device else { return }
        
        do {
            try device.lockForConfiguration()
            
            // æ›å…‰è¡¥å¿èŒƒå›´é€šå¸¸æ˜¯ -2.0 åˆ° +2.0
            let exposureValue = Float(value * 4.0 - 2.0)  // å°† 0-1 æ˜ å°„åˆ° -2 åˆ° +2
            let clampedValue = max(device.minExposureTargetBias, min(device.maxExposureTargetBias, exposureValue))
            
            device.setExposureTargetBias(clampedValue)
            
            device.unlockForConfiguration()
        } catch {
            print("è°ƒèŠ‚äº®åº¦å¤±è´¥: \(error.localizedDescription)")
        }
    }
    
    // MARK: - è°ƒèŠ‚ç¼©æ”¾
    func setZoom(_ value: Double) {
        guard let device = videoDeviceInput?.device else { return }
        
        do {
            try device.lockForConfiguration()
            
            // ç¼©æ”¾èŒƒå›´ï¼š1.0 åˆ°æœ€å¤§ç¼©æ”¾å€¼ï¼ˆé€šå¸¸æ˜¯ 5-10 å€ï¼‰
            let maxZoom = min(device.activeFormat.videoMaxZoomFactor, 5.0)  // é™åˆ¶æœ€å¤§5å€
            let zoomFactor = 1.0 + (maxZoom - 1.0) * CGFloat(value)
            
            device.videoZoomFactor = zoomFactor
            
            device.unlockForConfiguration()
        } catch {
            print("è°ƒèŠ‚ç¼©æ”¾å¤±è´¥: \(error.localizedDescription)")
        }
    }
    
    // MARK: - åˆ‡æ¢æ‰‹ç”µç­’
    func toggleTorch() {
        guard let device = videoDeviceInput?.device else { return }
        
        // æ£€æŸ¥è®¾å¤‡æ˜¯å¦æ”¯æŒæ‰‹ç”µç­’
        guard device.hasTorch && device.isTorchAvailable else {
            print("è®¾å¤‡ä¸æ”¯æŒæ‰‹ç”µç­’åŠŸèƒ½")
            return
        }
        
        do {
            try device.lockForConfiguration()
            
            if isTorchOn {
                // å…³é—­æ‰‹ç”µç­’
                device.torchMode = .off
                isTorchOn = false
            } else {
                // å¼€å¯æ‰‹ç”µç­’
                device.torchMode = .on
                isTorchOn = true
            }
            
            device.unlockForConfiguration()
        } catch {
            print("åˆ‡æ¢æ‰‹ç”µç­’å¤±è´¥: \(error.localizedDescription)")
        }
    }
    
    // MARK: - ç®€å•ç›´æ¥çš„è£å‰ªæ–¹æ³•ï¼ˆæ‰€è§å³æ‰€å¾—ï¼‰
    func cropImageUsingPreviewLayer(_ image: UIImage) -> UIImage {
        print("ğŸ” å¼€å§‹è£å‰ªï¼š")
        print("  - å–æ™¯æ¡†ä¿¡æ¯: \(viewportRect)")
        
        guard viewportRect != .zero else {
            print("âš ï¸ ç¼ºå°‘å–æ™¯æ¡†ä¿¡æ¯ï¼Œè¿”å›åŸå›¾")
            return image
        }
        
        // è·å–å±å¹•å°ºå¯¸
        guard let windowScene = UIApplication.shared.connectedScenes.first as? UIWindowScene,
              let window = windowScene.windows.first else {
            print("âš ï¸ æ— æ³•è·å–å±å¹•å°ºå¯¸ï¼Œè¿”å›åŸå›¾")
            return image
        }
        
        let screenWidth = window.bounds.width
        let screenHeight = window.bounds.height
        
        print("ğŸ“¸ è£å‰ªä¿¡æ¯ï¼š")
        print("  - ç…§ç‰‡å°ºå¯¸: \(image.size.width) Ã— \(image.size.height)")
        print("  - å±å¹•å°ºå¯¸: \(screenWidth) Ã— \(screenHeight)")
        print("  - å–æ™¯æ¡†: \(viewportRect)")
        
        // è®¡ç®—å–æ™¯æ¡†åœ¨å±å¹•ä¸Šçš„ç›¸å¯¹ä½ç½®ï¼ˆæ¯”ä¾‹ï¼‰
        let topRatio = viewportRect.origin.y / screenHeight
        let leftRatio = viewportRect.origin.x / screenWidth
        let widthRatio = viewportRect.width / screenWidth
        let heightRatio = viewportRect.height / screenHeight
        
        print("  - å–æ™¯æ¡†æ¯”ä¾‹: top=\(topRatio), left=\(leftRatio), width=\(widthRatio), height=\(heightRatio)")
        
        // æŒ‰ç›¸åŒæ¯”ä¾‹è£å‰ªç…§ç‰‡
        let imageWidth = image.size.width
        let imageHeight = image.size.height
        
        let cropX = leftRatio * imageWidth
        let cropY = topRatio * imageHeight
        let cropWidth = widthRatio * imageWidth
        let cropHeight = heightRatio * imageHeight
        
        print("  - è£å‰ªåŒºåŸŸ: x=\(cropX), y=\(cropY), w=\(cropWidth), h=\(cropHeight)")
        
        // ä½¿ç”¨ UIImage çš„è£å‰ªæ–¹æ³•ï¼ˆè‡ªåŠ¨å¤„ç†æ–¹å‘ï¼‰
        let cropRect = CGRect(x: cropX, y: cropY, width: cropWidth, height: cropHeight)
        
        // ç»˜åˆ¶è£å‰ªåçš„å›¾ç‰‡
        UIGraphicsBeginImageContextWithOptions(cropRect.size, false, image.scale)
        defer { UIGraphicsEndImageContext() }
        
        image.draw(at: CGPoint(x: -cropX, y: -cropY))
        
        guard let croppedImage = UIGraphicsGetImageFromCurrentImageContext() else {
            print("  âš ï¸ è£å‰ªå¤±è´¥ï¼Œè¿”å›åŸå›¾")
            return image
        }
        
        print("  âœ… è£å‰ªæˆåŠŸï¼æœ€ç»ˆå°ºå¯¸: \(croppedImage.size.width) Ã— \(croppedImage.size.height)")
        
        return croppedImage
    }
    
    // MARK: - æ°´å¹³ç¿»è½¬å›¾ç‰‡ï¼ˆç”¨äºå‰ç½®æ‘„åƒå¤´é•œåƒæ•ˆæœï¼‰
    private func flipImageHorizontally(_ image: UIImage) -> UIImage {
        guard let cgImage = image.cgImage else { return image }
        
        // åˆ›å»ºç¿»è½¬åçš„å›¾ç‰‡ï¼ˆæ°´å¹³é•œåƒï¼‰
        let flippedImage = UIImage(
            cgImage: cgImage,
            scale: image.scale,
            orientation: .upMirrored  // æ°´å¹³ç¿»è½¬
        )
        
        // é‡æ–°ç»˜åˆ¶ä»¥ç¡®ä¿ç¿»è½¬ç”Ÿæ•ˆ
        UIGraphicsBeginImageContextWithOptions(image.size, false, image.scale)
        defer { UIGraphicsEndImageContext() }
        
        flippedImage.draw(in: CGRect(origin: .zero, size: image.size))
        
        return UIGraphicsGetImageFromCurrentImageContext() ?? image
    }
    
    // MARK: - åº”ç”¨æ»¤é•œ
    func applyFilter(to image: UIImage, filterName: String) -> UIImage {
        // å¦‚æœæ˜¯åŸå›¾æ»¤é•œï¼Œç›´æ¥è¿”å›
        if filterName == "CIPhotoEffectNone" {
            return image
        }
        
        guard let ciImage = CIImage(image: image) else {
            print("âš ï¸ æ— æ³•åˆ›å»ºCIImage")
            return image
        }
        
        // åˆ›å»ºæ»¤é•œ
        guard let filter = CIFilter(name: filterName) else {
            print("âš ï¸ æ— æ³•åˆ›å»ºæ»¤é•œ: \(filterName)")
            return image
        }
        
        filter.setValue(ciImage, forKey: kCIInputImageKey)
        
        // è·å–è¾“å‡ºå›¾åƒ
        guard let outputImage = filter.outputImage else {
            print("âš ï¸ æ»¤é•œå¤„ç†å¤±è´¥")
            return image
        }
        
        // è½¬æ¢ä¸ºUIImage
        let context = CIContext()
        guard let cgImage = context.createCGImage(outputImage, from: outputImage.extent) else {
            print("âš ï¸ æ— æ³•åˆ›å»ºCGImage")
            return image
        }
        
        let filteredImage = UIImage(cgImage: cgImage, scale: image.scale, orientation: image.imageOrientation)
        print("âœ… å·²åº”ç”¨æ»¤é•œ: \(filterName)")
        
        return filteredImage
    }
}

// MARK: - AVCapturePhotoCaptureDelegate
extension VixenCameraOperator: AVCapturePhotoCaptureDelegate {
    func photoOutput(_ output: AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVCapturePhoto, error: Error?) {
        if let error = error {
            print("æ‹ç…§å¤±è´¥: \(error.localizedDescription)")
            return
        }
        
        guard let imageData = photo.fileDataRepresentation(),
              let image = UIImage(data: imageData) else {
            print("æ— æ³•è½¬æ¢å›¾ç‰‡æ•°æ®")
            return
        }
        
        // ç«‹å³è£å‰ªå›¾ç‰‡ï¼Œç¡®ä¿å±•ç¤ºçš„å°±æ˜¯æœ€ç»ˆä¿å­˜çš„
        var croppedImage = cropImageUsingPreviewLayer(image)
        
        // å¦‚æœæ˜¯å‰ç½®æ‘„åƒå¤´ï¼Œè¿›è¡Œæ°´å¹³ç¿»è½¬ï¼ˆé•œåƒæ•ˆæœï¼‰
        if self.currentCameraPosition == .front {
            croppedImage = self.flipImageHorizontally(croppedImage)
            print("ğŸ“¸ å‰ç½®æ‘„åƒå¤´ï¼Œå·²è¿›è¡Œæ°´å¹³ç¿»è½¬")
        }
        
        // åº”ç”¨æ»¤é•œ
        let filteredImage = self.applyFilter(to: croppedImage, filterName: self.currentFilter)
        
        DispatchQueue.main.async {
            self.capturedImage = filteredImage
        }
    }
}

